{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assuming we have a dataframe with corpus/frequency data (Futrell et al., 2021) combined with GPT-2 surprisal and cosine similarities"
      ],
      "metadata": {
        "id": "xgSz2jVs_Kdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(lme4)\n",
        "library(data.table)\n",
        "library(dplyr)\n",
        "library(ggplot2)\n",
        "library(broom.mixed)\n",
        "library(tibble)\n"
      ],
      "metadata": {
        "id": "daRq-R-EDFdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Surprisal Data"
      ],
      "metadata": {
        "id": "JAekOFd2E9Ya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kGkV6Ja-vt3"
      },
      "outputs": [],
      "source": [
        "surprisal_data = read_csv(\"gpt2_NS.csv\") %>%\n",
        "  separate(label, into = c(\"label\", \"label_num\"), sep = \"/\") %>%\n",
        "  mutate(label_num = str_trim(str_replace(label_num, pattern = \".word\", replacement = \"\")))\n",
        "\n",
        "story_info_surp = story_info %>%\n",
        "  left_join(surprisal_data, by=c(\"word_num\" = \"label_num\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to extract ERP data from raw EEG"
      ],
      "metadata": {
        "id": "WDOerQ41E_N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_ERP = function(subject, word_num, all_data, story_info,\n",
        "                       ERP_window_start = -750, ERP_window_end = 1500,\n",
        "                       channels ){\n",
        "  cat(subject, \"\\n\", word_num)\n",
        "  word_onset = story_info$Onset[story_info$word_num == word_num]*1000\n",
        "  word_onset_bin = round(word_onset/10)*10\n",
        "  #cat(word_onset)\n",
        "  story = story_info$Filename[story_info$word_num == word_num]\n",
        "  #cat(story)\n",
        "\n",
        "  ERP_data = all_data %>%\n",
        "    filter(StoryFilename == story & Subject == subject) %>%\n",
        "    filter(between(timebin_rel_story_onset, word_onset_bin + ERP_window_start, word_onset_bin+ERP_window_end))\n",
        "\n",
        "  ERP_baseline_data = ERP_data %>%\n",
        "    filter(between(timebin_rel_story_onset, word_onset_bin + ERP_window_start, word_onset_bin)) %>%\n",
        "    dplyr::select(all_of(channels))\n",
        "\n",
        "  ERP_baselines = colMeans(ERP_baseline_data)\n",
        "  #cat(ERP_baselines[\"Fp1\"][1])\n",
        "\n",
        "  #ERP_window_end_rd = if_else(length(ERP_data$timebin_rel_story_onset)==120, ERP_window_end-10, ERP_window_end)\n",
        "\n",
        "  ERP_data_baselined = ERP_data %>%\n",
        "    dplyr::select(all_of(channels), StoryFilename, Subject, timebin_rel_story_onset) %>%\n",
        "    mutate(word_num = word_num,\n",
        "           word_onset_bin = word_onset_bin,\n",
        "           across(all_of(channels), ~ .x - ERP_baselines[cur_column()][1], .names = \"{.col}_b\"),\n",
        "           timebin = seq(from=ERP_window_start, to = ERP_window_end, by=10))\n",
        "\n",
        "  return(ERP_data_baselined)\n",
        "}"
      ],
      "metadata": {
        "id": "CO7Bso7EAOYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Align stories and subjects"
      ],
      "metadata": {
        "id": "zukZqIMVFDNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story_info_surp$word_num %>% unique() %>% length()\n",
        "# 10310\n",
        "\n",
        "good_word_nums = story_info_surp %>% filter(!is.na(label)) %>% pull(word_num)\n",
        "good_word_nums %>% length()\n",
        "# 5203\n",
        "\n",
        "subjects <- unique(all_data$Subject)\n",
        "\n",
        "erps = expand_grid(subjects, good_word_nums)\n",
        "erps <- erps %>% mutate(story = sub(\"\\\\..*\", \"\", good_word_nums))\n",
        "erps$story <- as.numeric(erps$story)\n",
        "erps$subjects %>% length()\n",
        "\n",
        "# Create a new dataframe with unique subjects and their associated story filenames\n",
        "unique_subjects_df <- all_data %>%\n",
        "  group_by(Subject) %>%\n",
        "  summarise(Story_Filenames = list(unique(StoryFilename))) %>%\n",
        "  ungroup()\n",
        "\n",
        "story_lookup <- unique_subjects_df %>%\n",
        "  select(Subject, Story_Filenames) %>%\n",
        "  deframe()\n",
        "\n",
        "# Function to filter based on story lookup\n",
        "filter_stories <- function(subject, story) {\n",
        "  if (subject %in% names(story_lookup)) {\n",
        "    return(story %in% story_lookup[[subject]])\n",
        "  } else {\n",
        "    return(FALSE)\n",
        "  }\n",
        "}\n",
        "\n",
        "# Filter df2 based on the lookup list\n",
        "erps <- erps %>%\n",
        "  rowwise() %>%\n",
        "  mutate(valid_story = filter_stories(subjects, story)) %>%\n",
        "  filter(valid_story) %>%\n",
        "  select(-valid_story) %>%\n",
        "  ungroup()\n",
        "\n",
        "all_erp_data = map2_df(.x=erps$subjects, .y=erps$good_word_nums, .f=~extract_ERP(subject = .x, word_num=.y, all_data = all_data, story_info = story_info_surp, channels = channel_names$X2 ))\n",
        "saveRDS(all_erp_data, \"all_erp_data.rds\")\n"
      ],
      "metadata": {
        "id": "xdSpVOr3Arg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Align surprisal and ERP data"
      ],
      "metadata": {
        "id": "B6TdxyUNFQJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "firstQ = summary(story_info_surp$LSTM_batchnhid)[[2]]\n",
        "thirdQ = summary(story_info_surp$LSTM_batchnhid)[[5]]\n",
        "\n",
        "all_erp_data_surps = erp_data %>%\n",
        "  left_join(story_info_surp, by = \"word_num\") %>%\n",
        "  #select(-all_of(channel_names$X2)) %>%\n",
        "  mutate(LSTM_surprisal_cat = case_when(\n",
        "    LSTM_batchnhid <= firstQ ~ \"low\",\n",
        "    LSTM_batchnhid > firstQ & RNN < thirdQ ~ \"mid\",\n",
        "    LSTM_batchnhid >= thirdQ ~ \"high\"))\n",
        "\n",
        "all_erp_data_surps <- all_erp_data_surps %>%\n",
        "  mutate(LSTM_surprisal_cat = case_when(\n",
        "    LSTM_batchnhid <= firstQ ~ \"low\",\n",
        "    LSTM_batchnhid > firstQ & LSTM_batchnhid < thirdQ ~ \"mid\",\n",
        "    LSTM_batchnhid >= thirdQ ~ \"high\"))\n",
        "\n",
        "  all_erp_data_surps2  = all_erp_data_surps %>%\n",
        "  #sample_n(20) %>%\n",
        "  rowwise() %>%\n",
        "  mutate(\n",
        "    AvgN4channels = mean(c(Cz_b, C1_b, C2_b, C3_b, C4_b, CPz_b, CP1_b,\n",
        "                           CP2_b, CP3_b, CP4_b, Pz_b, P1_b, P2_b, P3_b,\n",
        "                           P4_b)))"
      ],
      "metadata": {
        "id": "pG6wztjLA-Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create ERP data for each time window in the epoch"
      ],
      "metadata": {
        "id": "y7VqydCfFXEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_erp_data_surps2 <- as.data.table(readRDS(\"all_erp_data_surps2_complete.rds\"))\n",
        "\n",
        "N4_data_surps_200_0 = all_erp_data_surps2 %>%\n",
        "  filter(timebin >= -200 & timebin <= 0) %>%\n",
        "  group_by(Subject, word_num, StoryFilename, full_word, sentpos, RNN, LSTM_batchnhid, residuals_ltanh_batchnhid, LSTM_surprisal_cat, frequency, word_cos_sim, Duration, gpt3_probs, sentid) %>%\n",
        "  summarize(meanN4 = mean(AvgN4channels)) %>%\n",
        "  mutate(wlen = nchar(full_word))\n",
        "\n",
        "N4_data_surps_200_0$prev_freq <- lead(N4_data_surps_200_0$frequency, n = 1)\n",
        "N4_data_surps_200_0$prev_word_cos_sim <- lead(N4_data_surps_200_0$word_cos_sim, n = 1)\n",
        "N4_data_surps_200_0$prev_surp <- lead(N4_data_surps_200_0$gpt3_probs, n = 1)\n",
        "\n",
        "N4_data_surps_0_200 = all_erp_data_surps2 %>%\n",
        "  filter(timebin >= 0 & timebin <= 200) %>%\n",
        "  group_by(Subject, word_num, StoryFilename, full_word, sentpos, RNN, LSTM_batchnhid, residuals_ltanh_batchnhid, LSTM_surprisal_cat, frequency, word_cos_sim, Duration, gpt3_probs, sentid) %>%\n",
        "  summarize(meanN4 = mean(AvgN4channels)) %>%\n",
        "  mutate(wlen = nchar(full_word))\n",
        "\n",
        "N4_data_surps_100_100 = all_erp_data_surps2 %>%                                                                                          filter(timebin >= -100 & timebin <= 100) %>%                                                                                           group_by(Subject, word_num, StoryFilename, full_word, sentpos, RNN, LSTM_batchnhid, residuals_ltanh_batchnhid, LSTM_surprisal_cat, frequency, word_cos_sim, Duration, gpt3_probs, sentid) %>%\n",
        "  summarize(meanN4 = mean(AvgN4channels)) %>%\n",
        "  mutate(wlen = nchar(full_word))\n",
        "\n",
        "N4_data_surps_100_100$prev_freq <- lead(N4_data_surps_100_100$frequency, n = 1)\n",
        "N4_data_surps_100_100$prev_word_cos_sim <- lead(N4_data_surps_100_100$word_cos_sim, n = 1)\n",
        "N4_data_surps_100_100$prev_surp <- lead(N4_data_surps_100_100$gpt3_probs, n = 1)\n",
        "\n",
        "N4_data_surps_0_200$prev_freq <- lead(N4_data_surps_0_200$frequency, n = 1)\n",
        "N4_data_surps_0_200$prev_word_cos_sim <- lead(N4_data_surps_0_200$word_cos_sim, n = 1)\n",
        "N4_data_surps_0_200$prev_surp <- lead(N4_data_surps_0_200$gpt3_probs, n = 1)\n",
        "\n",
        "N4_data_surps_100_300 = all_erp_data_surps2 %>%\n",
        "  filter(timebin >= 100 & timebin <= 300) %>%\n",
        "  group_by(Subject, word_num, StoryFilename, full_word, sentpos, RNN, LSTM_batchnhid, residuals_ltanh_batchnhid, LSTM_surprisal_cat, frequency, word_cos_sim, Duration, gpt3_probs, sentid) %>%\n",
        "  summarize(meanN4 = mean(AvgN4channels)) %>%\n",
        "  mutate(wlen = nchar(full_word))\n",
        "\n",
        "N4_data_surps_100_300$prev_freq <- lead(N4_data_surps_100_300$frequency, n = 1)\n",
        "N4_data_surps_100_300$prev_word_cos_sim <- lead(N4_data_surps_100_300$word_cos_sim, n = 1)\n",
        "N4_data_surps_100_300$prev_surp <- lead(N4_data_surps_100_300$gpt3_probs, n = 1)\n",
        "\n",
        "N4_data_surps_200_400 = all_erp_data_surps2 %>%\n",
        "  filter(timebin >= 200 & timebin <= 400) %>%\n",
        "  group_by(Subject, word_num, StoryFilename, full_word, sentpos, RNN, LSTM_batchnhid, residuals_ltanh_batchnhid, LSTM_surprisal_cat, frequency, word_cos_sim, Duration, gpt3_probs, sentid) %>%\n",
        "  summarize(meanN4 = mean(AvgN4channels)) %>%\n",
        "  mutate(wlen = nchar(full_word))\n",
        "\n",
        "N4_data_surps_200_400$prev_freq <- lead(N4_data_surps_200_400$frequency, n = 1)\n",
        "N4_data_surps_200_400$prev_word_cos_sim <- lead(N4_data_surps_200_400$word_cos_sim, n = 1)\n",
        "N4_data_surps_200_400$prev_surp <- lead(N4_data_surps_200_400$gpt3_probs, n = 1)\n",
        "\n",
        "N4_data_surps_300_500 = all_erp_data_surps2 %>%\n",
        "  filter(timebin >= 300 & timebin <= 500) %>%\n",
        "  group_by(Subject, word_num, StoryFilename, full_word, sentpos, RNN, LSTM_batchnhid, residuals_ltanh_batchnhid, LSTM_surprisal_cat, frequency, word_cos_sim, Duration, gpt3_probs, sentid) %>%\n",
        "  summarize(meanN4 = mean(AvgN4channels)) %>%\n",
        "  mutate(wlen = nchar(full_word))\n",
        "\n",
        "N4_data_surps_300_500$prev_freq <- lead(N4_data_surps_300_500$frequency, n = 1)\n",
        "N4_data_surps_300_500$prev_word_cos_sim <- lead(N4_data_surps_300_500$word_cos_sim, n = 1)\n",
        "N4_data_surps_300_500$prev_surp <- lead(N4_data_surps_300_500$gpt3_probs, n = 1)\n",
        "\n",
        "N4_data_surps_400_600 = all_erp_data_surps2 %>%\n",
        "  filter(timebin >= 400 & timebin <= 600) %>%\n",
        "  group_by(Subject, word_num, StoryFilename, full_word, sentpos, RNN, LSTM_batchnhid, residuals_ltanh_batchnhid, LSTM_surprisal_cat, frequency, word_cos_sim, Duration, gpt3_probs, sentid) %>%\n",
        "  summarize(meanN4 = mean(AvgN4channels)) %>%\n",
        "  mutate(wlen = nchar(full_word))\n",
        "\n",
        "N4_data_surps_400_600$prev_freq <- lead(N4_data_surps_400_600$frequency, n = 1)\n",
        "N4_data_surps_400_600$prev_word_cos_sim <- lead(N4_data_surps_400_600$word_cos_sim, n = 1)\n",
        "N4_data_surps_400_600$prev_surp <- lead(N4_data_surps_400_600$gpt3_probs, n = 1)\n",
        "\n",
        "N4_data_surps_500_700 = all_erp_data_surps2 %>%\n",
        "  filter(timebin >= 500 & timebin <= 700) %>%\n",
        "  group_by(Subject, word_num, StoryFilename, full_word, sentpos, RNN, LSTM_batchnhid, residuals_ltanh_batchnhid, LSTM_surprisal_cat, frequency, word_cos_sim, Duration, gpt3_probs, sentid) %>%\n",
        "  summarize(meanN4 = mean(AvgN4channels)) %>%\n",
        "  mutate(wlen = nchar(full_word))\n",
        "\n",
        "N4_data_surps_500_700$prev_freq <- lead(N4_data_surps_500_700$frequency, n = 1)\n",
        "N4_data_surps_500_700$prev_word_cos_sim <- lead(N4_data_surps_500_700$word_cos_sim, n = 1)\n",
        "N4_data_surps_500_700$prev_surp <- lead(N4_data_surps_500_700$gpt3_probs, n = 1)\n",
        "\n",
        "N4_data_surps_600_800 = all_erp_data_surps2 %>%\n",
        "  filter(timebin >= 600 & timebin <= 800) %>%\n",
        "  group_by(Subject, word_num, StoryFilename, full_word, sentpos, RNN, LSTM_batchnhid, residuals_ltanh_batchnhid, LSTM_surprisal_cat, frequency, word_cos_sim, Duration, gpt3_probs, sentid) %>%\n",
        "  summarize(meanN4 = mean(AvgN4channels)) %>%\n",
        "  mutate(wlen = nchar(full_word))\n",
        "\n",
        "N4_data_surps_600_800$prev_freq <- lead(N4_data_surps_600_800$frequency, n = 1)\n",
        "N4_data_surps_600_800$prev_word_cos_sim <- lead(N4_data_surps_600_800$word_cos_sim, n = 1)\n",
        "N4_data_surps_600_800$prev_surp <- lead(N4_data_surps_600_800$gpt3_probs, n = 1)\n",
        "\n",
        "N4_data_surps_700_900 = all_erp_data_surps2 %>%\n",
        "  filter(timebin >= 700 & timebin <= 900) %>%\n",
        "  group_by(Subject, word_num, StoryFilename, full_word, sentpos, RNN, LSTM_batchnhid, residuals_ltanh_batchnhid, LSTM_surprisal_cat, frequency, word_cos_sim, Duration, gpt3_probs, sentid) %>%\n",
        "  summarize(meanN4 = mean(AvgN4channels)) %>%\n",
        "  mutate(wlen = nchar(full_word))\n",
        "\n",
        "N4_data_surps_700_900$prev_freq <- lead(N4_data_surps_700_900$frequency, n = 1)\n",
        "N4_data_surps_700_900$prev_word_cos_sim <- lead(N4_data_surps_700_900$word_cos_sim, n = 1)\n",
        "N4_data_surps_700_900$prev_surp <- lead(N4_data_surps_700_900$gpt3_probs, n = 1)\n",
        "\n",
        "N4_data_surps_800_1000 = all_erp_data_surps2 %>%\n",
        "  filter(timebin >= 800 & timebin <= 1000) %>%\n",
        "  group_by(Subject, word_num, StoryFilename, full_word, sentpos, RNN, LSTM_batchnhid, residuals_ltanh_batchnhid, LSTM_surprisal_cat, frequency, word_cos_sim, Duration, gpt3_probs, sentid) %>%\n",
        "  summarize(meanN4 = mean(AvgN4channels)) %>%\n",
        "  mutate(wlen = nchar(full_word))\n",
        "\n",
        "N4_data_surps_800_1000$prev_freq <- lead(N4_data_surps_800_1000$frequency, n = 1)\n",
        "N4_data_surps_800_1000$prev_word_cos_sim <- lead(N4_data_surps_800_1000$word_cos_sim, n = 1)\n",
        "N4_data_surps_800_1000$prev_surp <- lead(N4_data_surps_800_1000$gpt3_probs, n = 1)\n",
        "\n",
        "\n",
        "#vanilla_lmer <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_300_500)\n",
        "\n",
        "#saveRDS(vanilla_lmer, \"vanilla_fullresidlm4.rds\")\n",
        "\n",
        "#myvar <- allFit(vanilla_lmer)\n",
        "\n",
        "#saveRDS(myvar, \"allfitresid_vanilla.rds\")\n",
        "\n",
        "#lm1 <- lmer(meanN4 ~ scale(residuals_ltanh_batchnhid) + scale(log(frequency)) + scale(log(prev_freq)) + scale(word_cos_sim) + scale(prev_word_cos_sim) + scale(gpt3_probs) + scale(prev_surp) + scale(Duration) + scale(sentpos) + scale(sentid) + (1|full_word) + (1|StoryFilename) + (1 + scale(residuals_ltanh_batchnhid) + scale(log(frequency)) + scale(log(prev_freq)) + scale(word_cos_sim) + scale(prev_word_cos_sim) + scale(gpt3_probs) + scale(prev_surp) + scale(Duration) + scale(sentpos) + scale(sentid) | Subject), data = N4_data_surps_0_200, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "#saveRDS(lm1, \"scalefullresidlm1.rds\")\n",
        "\n",
        "lm1 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_0_200, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "saveRDS(lm1, \"fulloptresidlm1.rds\")\n",
        "\n",
        "#lm2 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|full_word) + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid | Subject), data = N4_data_surps_100_300)\n",
        "\n",
        "#saveRDS(lm2, \"fullresidlm2.rds\")\n",
        "\n",
        "lm2 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_100_300, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "saveRDS(lm2, \"fulloptresidlm2.rds\")\n",
        "\n",
        "#lm3 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|full_word) + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid | Subject), data = N4_data_surps_200_400)\n",
        "\n",
        "#saveRDS(lm3, \"fullresidlm3.rds\")\n",
        "\n",
        "lm3 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_200_400, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "saveRDS(lm3, \"fulloptresidlm3.rds\")\n",
        "\n",
        "#lm4 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid || Subject), data = N4_data_surps_300_500)\n",
        "\n",
        "#saveRDS(lm4, \"fullresidlm4_nofullword.rds\")\n",
        "\n",
        "#myvar <- allFit(lm4)\n",
        "\n",
        "#saveRDS(myvar, \"allfitresid_n400output.rds\")\n",
        "\n",
        "lm4 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_300_500, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "saveRDS(lm4, \"fulloptresidlm4.rds\")\n",
        "\n",
        "#lm5 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|full_word) + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid | Subject), data = N4_data_surps_400_600)\n",
        "\n",
        "#saveRDS(lm5, \"fullresidlm5.rds\")\n",
        "\n",
        "lm5 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_400_600, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "saveRDS(lm5, \"fulloptresidlm5.rds\")\n",
        "\n",
        "#lm6 <- lmer(meanN4 ~ scale(residuals_ltanh_batchnhid) + scale(log(frequency)) + scale(log(prev_freq)) + scale(word_cos_sim) + scale(prev_word_cos_sim) + scale(gpt3_probs) + scale(prev_surp) + scale(Duration) + scale(sentpos) + (1|full_word) + (1|StoryFilename) + (1 + scale(residuals_ltanh_batchnhid) + scale(log(frequency)) + scale(log(prev_freq)) + scale(word_cos_sim) + scale(prev_word_cos_sim) + scale(gpt3_probs) + scale(prev_surp) + scale(Duration) + scale(sentpos) || Subject), data = N4_data_surps_500_700)\n",
        "\n",
        "#lm6 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|full_word) + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid | Subject), data = N4_data_surps_500_700, control = lmerControl(optimizer = \"bobyqa\", , optCtrl = list(maxfun = 5e+05)))\n",
        "\n",
        "#saveRDS(lm6, \"fullresidlm6-optbobyqa.rds\")\n",
        "\n",
        "#my_var <- allFit(lm6)\n",
        "\n",
        "#saveRDS(my_var, \"allfitresid_output6.rds\")\n",
        "\n",
        "lm6 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_500_700, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "saveRDS(lm6, \"fulloptresidlm6.rds\")\n",
        "\n",
        "#lm7 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|full_word) + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid | Subject), data = N4_data_surps_600_800)\n",
        "\n",
        "#saveRDS(lm7, \"fullresidlm7.rds\")\n",
        "\n",
        "lm7 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_600_800, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "saveRDS(lm7, \"fulloptresidlm7.rds\")\n",
        "\n",
        "#lm8 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|full_word) + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid | Subject), data = N4_data_surps_700_900)\n",
        "\n",
        "#saveRDS(lm8, \"fullresidlm8.rds\")\n",
        "\n",
        "lm8 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_700_900, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "saveRDS(lm8, \"fulloptresidlm8.rds\")\n",
        "\n",
        "#lm9 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|full_word) + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid | Subject), data = N4_data_surps_800_1000)\n",
        "\n",
        "#saveRDS(lm9, \"fullresidlm9.rds\")\n",
        "\n",
        "lm9 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_800_1000, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "saveRDS(lm9, \"fulloptresidlm9.rds\")\n",
        "\n",
        "lm10 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_100_100, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "saveRDS(lm10, \"fulloptresidlm10.rds\")\n",
        "\n",
        "lm11 <- lmer(meanN4 ~ residuals_ltanh_batchnhid + scale(log(frequency)) + scale(log(prev_freq)) + word_cos_sim + prev_word_cos_sim + gpt3_probs + prev_surp + Duration + sentpos + sentid + (1|StoryFilename) + (1 + residuals_ltanh_batchnhid + word_cos_sim + gpt3_probs || Subject), data = N4_data_surps_200_0, control=lmerControl(optimizer=\"bobyqa\", optCtrl=list(maxfun=2e5)))\n",
        "\n",
        "saveRDS(lm11, \"fulloptresidlm11.rds\")\n"
      ],
      "metadata": {
        "id": "-ohjJLNLBkv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set model and time window variables"
      ],
      "metadata": {
        "id": "waZspdjHFhf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models <- list(\n",
        "  lm11,  # -200–0\n",
        "  lm10,  # -100–100\n",
        "  lm1,   # 0–200\n",
        "  lm2,   # 100–300\n",
        "  lm3,   # 200–400\n",
        "  lm4,   # 300–500\n",
        "  lm5,   # 400–600\n",
        "  lm6,   # 500–700\n",
        "  lm7,   # 600–800\n",
        "  lm8,   # 700–900\n",
        "  lm9    # 800–1000\n",
        ")\n",
        "\n",
        "time_windows <- tibble(\n",
        "  window_id  = seq_along(models),\n",
        "  start_ms = c(-200, -100,   0, 100, 200, 300, 400, 500, 600, 700, 800),\n",
        "  end_ms   = c(   0,  100, 200, 300, 400, 500, 600, 700, 800, 900, 1000)\n",
        ") %>%\n",
        "  mutate(time_center = (start_ms + end_ms) / 2)\n",
        "\n"
      ],
      "metadata": {
        "id": "mfy_5UBlCgLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract fixed effects"
      ],
      "metadata": {
        "id": "1nyy-7NiFlzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictors_of_interest <- c(\n",
        "  \"gpt3_probs\",\n",
        "  \"residuals_ltanh_batchnhid\",\n",
        "  \"word_cos_sim\"\n",
        ")\n",
        "\n",
        "extract_model <- function(model, window_id) {\n",
        "  broom.mixed::tidy(model, effects = \"fixed\") %>%\n",
        "    filter(term %in% predictors_of_interest) %>%\n",
        "    mutate(window_id = window_id)\n",
        "}\n",
        "\n",
        "erp_results <- bind_rows(\n",
        "  lapply(seq_along(models), function(i) {\n",
        "    extract_model(models[[i]], i)\n",
        "  })\n",
        ")\n",
        "erp_results <- erp_results %>%\n",
        "  left_join(time_windows, by = \"window_id\") %>%\n",
        "  mutate(\n",
        "    ci_low  = estimate - 1.96 * std.error,\n",
        "    ci_high = estimate + 1.96 * std.error\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "id": "DAsuOL_9EpeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add time + confidence intervals, label predictors for facets"
      ],
      "metadata": {
        "id": "GcwsSfIgFrni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "erp_results <- erp_results %>%\n",
        "  mutate(\n",
        "    term_label = recode(\n",
        "      term,\n",
        "      \"gpt3_probs\"                = \"Surprisal β\",\n",
        "      \"residuals_ltanh_batchnhid\" = \"Residual β\",\n",
        "      \"word_cos_sim\"              = \"Cosine Similarity β\"\n",
        "    )\n",
        "  )\n",
        "\n",
        "erp_results$term_label <- factor(\n",
        "  erp_results$term_label,\n",
        "  levels = c(\"Surprisal β\", \"Residual β\", \"Cosine Similarity β\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "Sv8s95q1Ew7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot results to see where in the timecourse residual, surprisal, and cosine similarity are significant"
      ],
      "metadata": {
        "id": "9PHDw__ZFvAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(\n",
        "  erp_results,\n",
        "  aes(\n",
        "    x = time_center,\n",
        "    y = estimate,\n",
        "    color = term_label,\n",
        "    fill  = term_label\n",
        "  )\n",
        ") +\n",
        "  geom_ribbon(\n",
        "    aes(ymin = ci_low, ymax = ci_high),\n",
        "    alpha = 0.25,\n",
        "    linewidth = 0\n",
        "  ) +\n",
        "  geom_line(linewidth = 1) +\n",
        "  geom_hline(yintercept = 0, linewidth = 0.4) +\n",
        "  geom_vline(xintercept = 0, linewidth = 0.4) +\n",
        "  facet_wrap(~ term_label, ncol = 1, scales = \"free_y\") +\n",
        "  scale_color_manual(values = c(\n",
        "    \"Surprisal β\"         = \"#2C6BED\",\n",
        "    \"Residual β\"         = \"#C23B22\",\n",
        "    \"Cosine Similarity β\" = \"#8E44AD\"\n",
        "  )) +\n",
        "  scale_fill_manual(values = c(\n",
        "    \"Surprisal β\"         = \"#2C6BED\",\n",
        "    \"Residual β\"         = \"#C23B22\",\n",
        "    \"Cosine Similarity β\" = \"#8E44AD\"\n",
        "  )) +\n",
        "  labs(\n",
        "    x = \"Time Window (ms)\",\n",
        "    y = expression(beta * \"-value\")\n",
        "  ) +\n",
        "  theme_minimal(base_size = 12) +\n",
        "  theme(\n",
        "    strip.text = element_text(face = \"bold\"),\n",
        "    panel.grid.minor = element_blank(),\n",
        "    legend.position = \"none\"\n",
        "  )\n"
      ],
      "metadata": {
        "id": "nn8i-2I8EzDo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}